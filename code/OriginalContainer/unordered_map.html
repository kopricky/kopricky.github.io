<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title> My Algorithm : kopricky アルゴリズムライブラリ </title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="競技プログラミングで使われるアルゴリズムのコード集">
<meta name="keywords" content="競技プログラミング,競プロ,アルゴリズム,コード,kopricky,computation,datastructure,geometry,graph,networkflow,string,icpc,Atcoder">
<link rel="stylesheet" href="../../css/style.css">
<script type="text/javascript" src="../../js/openclose.js"></script>
<link href="https://use.fontawesome.com/releases/v5.0.6/css/all.css" rel="stylesheet">
<link rel="stylesheet" href="../../css/prettify.css" type="text/css">
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>

<body>

<div id="container">

<header>
<h1 id="logo"><a href="../../index.html"><img src="../../images/logo.png" alt="kopricky アルゴリズムライブラリ"></a></h1>
</header>


<nav id="menubar">
<ul>
<li><a href="../../index.html">Home</a></li>
<li><a href="../../guide.html">Guide</a></li>
<li class="current"><a href="../../code.html">Code</a></li>
<li><a href="../../link.html">Link</a></li>
</ul>
</nav>

<div id="contents">

<section>
<h2>Unordered Map</h2>
<h3>コードについての説明</h3>
<p>
hash を用いた連想配列クラスの実装である. std::unordered_map は
<a href="https://tessil.github.io/2016/08/29/benchmark-hopscotch-map.html">(参考 1)</a>, <a href="https://martin.ankerl.com/2019/04/01/hashmap-benchmarks-01-overview/">(参考 2)</a>
にあるように実行速度が遅いことが知られている. そこでこれらのベンチマークで良い性能を示している robin hood hashing を用いた unordered_map の実装を行ってみた. <br>
robin hood hashing のアルゴリズムはとても単純でこの <a href="http://web.stanford.edu/class/archive/cs/cs166/cs166.1166/lectures/13/Small13.pdf">Lecture pdf</a> の説明が分かりやすかった(他にも
<a href="https://www.sebastiansylvan.com/post/robin-hood-hashing-should-be-your-default-hash-table-implementation/">(参考 3)</a>, <a href="https://www.sebastiansylvan.com/post/more-on-robin-hood-hashing-2/">(参考 4)</a> を参照した).
データの挿入時すでにバケットが埋まっていた場合, 愚直に空いているバケットを探索する linear probing と異なり, 今挿入しようとしているデータとすでにバケットに存在するデータとを比べて自分のほうが本来のバケット位置との距離が小さかったら swap する, そうでなければそのまま探索を続ける.
という操作を空いているバケットが見つかるまで繰り返す. イメージで言うと富の再分配的な感じで本来のバケット位置に近いデータが遠いデータにバケットを譲ってあげるというトリックが用いられている.
こうすることで linear probing と各データの本来のバケット位置からの距離, つまり探索距離の総和は変化しないもののその分散が小さくなっている.
robin hood hashing はキャッシュに乗りやすいのが高速になる 1 つの要因で, 同じ資料に Cuckoo Hashing が紹介されていて理論計算量は良いものの, 明らかに 2 つのテーブル間の移動においてキャシュミスが起きていてあまり速くならなさそうな気はする(ただ計算量解析はおもしろかった). <br>
robin hood hashing の期待計算量はハッシュ関数が真にランダムの場合, O(log log n) でより詳しい計算量解析(concentration など) については <a href="http://luc.devroye.org/robinhood.pdf">この論文</a> が参考になりそう(まだ読んでいない). <br>
また delete の際に<a href="http://codecapsule.com/2013/11/17/robin-hood-hashing-backward-shift-deletion/">このページ</a>にあるような backward shift を行うと実測が速くなるようなので採用させていただいた.
具体的には要素を削除した際に, その後に続くバケットを見てバケットが空もしくは本来のバケット位置にいるデータを見つけるまでの要素をすべて後ろに 1 つシフトするということをする. <br>
以下の実装はある程度 std::unordered_map と同様に動作するが, ムーブセマンティクスなどは実装していない. 自作のハッシュ関数を使う場合は第 3 テンプレート引数として与える. 第 4 引数については最後に書く.
デフォルトでは std::hash を用いてますが入力に偏りなどあるとすぐ <b>衝突しまくる</b> ので <a href="../Misc/hash_function.html">こちら</a> を参考に murmur hash などましなハッシュ関数を引数として与えることを <b>強くおすすめします</b>. <br>
速度を重視したので rahash が起きると <b>イテレーター破壊</b> が起きます!!(逆に言えば find, insert, erase などの操作をしなければイテレーター破壊は起きません.) <br>
実装は普通のコードと高速版のコードが置いてあり, 高速版の方は int 型や long long 型などに対してのみ用いてください(具体的には一致判定が高速にできるような型に対して用いる). つまりキー値に string などを用いる場合は 1 つ目のコードを使ってください. <br>
(細かい実装の話) <br>
キャッシュミスを防ぐために違和感はあるが dist や hash を data ではなく bucket に紐付けるようにしている. <br>
高速版の方はキャッシュに乗りやすいようなデータの持ち方をした結果イテレーターが普通の std::unordered_map などと異なりイテレーターの参照(*it)の型が pair&lt;const _Key&amp;, _Tp&amp;&gt; になっている. 普通は pair&lt;const _Key, _Tp&gt;&amp;. <br>
alignment 等を気にした結果 dist が short int だったり aligned_storage を用いたりなどしてあがいている. あとバケットのサイズは 2 べきにしています. 2 べきだと % ではなく & でバケットの位置を計算できて高速になりうるみたいな話を聞いたことがあったので.<br>
関数 maximum_distance() は現在のハッシュテーブルにおいて find の際の linear probing にかかる時間の最大値を求めていて, 速度がなぜか遅くなるみたいな場合はこれを用いることでハッシュの衝突がその原因になっているかどうかを確かめることができる.
先述のように真にランダムなハッシュ関数を用いた場合期待値 O(log log n) でまた理論的にはばらつきも小さいので maximum_distance() はちゃんとしたハッシュ関数を用いていればとても小さくなる. <br>
第 4 引数の DOWNSIZE は rehash でバケット数に対して要素数が少ないときにバケットのサイズを縮小させるかを表している. unordered_map を for_each でなめたり, erase したりなどは要素数だけでなくバケット数にも比例するので, バケットサイズの縮小をしないととても速度が遅くなることがあったので設けた. <br>
もう少し verify を重ねたい気はしている.
</p>
<h3>コード</h3>
<div class="codebox">
<input type="checkbox" id="label" class="csscode" />
<label for="label"></label>
<pre class="prettyprint linenums">
template&lt;class _Key, class _Tp, class _Hash, bool DOWNSIZE&gt; class UnorderedMapIterator;

template&lt;class _Key, class _Tp, class _Hash = hash&lt;_Key&gt;, bool DOWNSIZE = false&gt;
class UnorderedMap
{
private:
    using iterator = UnorderedMapIterator&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    using data_type = pair&lt;_Key, _Tp&gt;;
    using aligned_pointer = typename aligned_storage&lt;sizeof(data_type), alignof(data_type)&gt;::type;
    friend UnorderedMapIterator&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    struct bucket {
        unsigned int _hash;
        short int _dist;
        bool _last, _end;
        aligned_pointer _data_ptr;
        bucket() noexcept : _dist(-1), _last(false), _end(false){}
        ~bucket(){ if(!empty()) _delete(); }
        inline void clear() noexcept { _dist = -1; }
        inline void _delete(){ _dist = -1, data_ptr()-&gt;~data_type(); }
        inline bool empty() const noexcept { return (_dist == -1); }
        inline data_type&amp; data() noexcept {
            return *reinterpret_cast&lt;data_type*&gt;(&amp;_data_ptr);
        }
        inline data_type* data_ptr() noexcept {
            return reinterpret_cast&lt;data_type*&gt;(&amp;_data_ptr);
        }
        inline const _Key&amp; get_key() noexcept { return data_ptr()-&gt;first; }
        inline void new_data(const data_type&amp; data){
            new(&amp;_data_ptr) data_type(data);
        }
    };
    inline static unsigned int ceilpow2(unsigned int u) noexcept {
        --u, u |= u &gt;&gt; 1, u |= u &gt;&gt; 2, u |= u &gt;&gt; 4, u |= u &gt;&gt; 8;
        return (u | (u &gt;&gt; 16)) + 1;
    }
    inline static bucket *increment(bucket *cur) noexcept {
        for(++cur; !cur-&gt;_end; ++cur){
            if(!cur-&gt;empty()) break;
        }
        return cur;
    }
    inline bucket *next_bucket(bucket *cur) const noexcept {
        return cur-&gt;_last ? _buckets : cur + 1;
    }
    inline unsigned int make_hash(const _Key&amp; key) const noexcept {
        return _Hash()(key);
    }
    inline float load_factor() const noexcept {
        return (float)_data_count / _bucket_count;
    }
    bucket *insert_impl(bucket *cur, unsigned int hash, short int dist, data_type data){
        bucket *ret = cur;
        bool flag = false;
        while(true){
            if(cur-&gt;empty()){
                cur-&gt;_hash = hash, cur-&gt;_dist = dist, cur-&gt;new_data(data);
                if(!flag) ret = cur, flag = true;
                break;
            }else if(dist &gt; cur-&gt;_dist){
                swap(hash, cur-&gt;_hash), swap(dist, cur-&gt;_dist), swap(data, cur-&gt;data());
                if(!flag) ret = cur, flag = true;
            }
            ++dist;
            cur = next_bucket(cur);
        }
        return ret;
    }
    bucket *_find(const _Key&amp; key, bool push=false){
        unsigned int hash = make_hash(key);
        bucket *cur = _buckets + (hash &amp; _mask);
        short int dist = 0;
        while(dist &lt;= cur-&gt;_dist){
            if(hash == cur-&gt;_hash &amp;&amp; key == cur-&gt;get_key()){
                return cur;
            }
            ++dist;
            cur = next_bucket(cur);
        }
        if(!push) return _buckets + _bucket_count;
        ++_data_count;
        if(rehash_check()){
            hash = make_hash(key), cur = _buckets + (hash &amp; _mask), dist = 0;
        }
        return insert_impl(cur, hash, dist, data_type(key, _Tp()));
    }
    bucket *_insert(const data_type&amp; data){
        const _Key&amp; key = data.first;
        unsigned int hash = make_hash(key);
        bucket *cur = _buckets + (make_hash(hash) &amp; _mask);
        short int dist = 0;
        while(dist &lt;= cur-&gt;_dist){
            if(hash == cur-&gt;_hash &amp;&amp; key == cur-&gt;get_key()){
                return cur;
            }
            ++dist;
            cur = next_bucket(cur);
        }
        ++_data_count;
        if(rehash_check()){
            hash = make_hash(key), cur = _buckets + (hash &amp; _mask), dist = 0;
        }
        return insert_impl(cur, hash, dist, data);
    }
    bucket *backward_shift(bucket *cur, bool next_ret){
        bucket *next = next_bucket(cur), *ret = cur;
        if(next-&gt;_dist &lt; 1) return next_ret ? increment(cur) : cur;
        do {
            cur-&gt;_hash = next-&gt;_hash;
            cur-&gt;_dist = next-&gt;_dist - 1;
            cur-&gt;_data_ptr = next-&gt;_data_ptr;
            cur = next, next = next_bucket(cur);
        }while(next-&gt;_dist &gt;= 1);
        cur-&gt;clear();
        return ret;
    }
    bucket *erase_impl(bucket *cur, bool next_ret){
        assert(cur != _buckets + _bucket_count);
        cur-&gt;_delete();
        return backward_shift(cur, next_ret);
    }
    bucket *erase_itr(bucket *cur, bool next_ret = true){
        --_data_count;
        const _Key&amp; key = cur-&gt;get_key();
        return erase_impl(rehash_check() ? _find(key) : cur, next_ret);
    }
    bucket *erase_key(const _Key&amp; key, bool next_ret = true){
        --_data_count;
        rehash_check();
        return erase_impl(_find(key), next_ret);
    }
    bool rehash_check(){
        if(load_factor() &gt;= MAX_LOAD_FACTOR){
            rehash(_bucket_count * 2);
            return true;
        }else if(DOWNSIZE){
            if(load_factor() &lt;= MIN_LOAD_FACTOR &amp;&amp; _bucket_count &gt;= DOWNSIZE_THRESHOLD){
                rehash(_bucket_count / 2);
                return true;
            }else{
                return false;
            }
        }else{
            return false;
        }
    }
    void move_data(aligned_pointer data_ptr){
        unsigned int hash = make_hash(reinterpret_cast&lt;data_type*&gt;(&amp;data_ptr)-&gt;first);
        bucket *cur = _buckets + (hash &amp; _mask);
        short int dist = 0;
        while(true){
            if(cur-&gt;empty()){
                cur-&gt;_hash = hash, cur-&gt;_dist = dist, cur-&gt;_data_ptr = data_ptr;
                break;
            }else if(dist &gt; cur-&gt;_dist){
                swap(hash, cur-&gt;_hash), swap(dist, cur-&gt;_dist), swap(data_ptr, cur-&gt;_data_ptr);
            }
            ++dist;
            cur = next_bucket(cur);
        }
    }
    void rehash(unsigned int new_bucket_count){
        UnorderedMap new_unordered_map(new_bucket_count);
        new_unordered_map._data_count = _data_count;
        for(bucket *cur = _buckets; !cur-&gt;_end; ++cur){
            if(!cur-&gt;empty()){
                new_unordered_map.move_data(cur-&gt;_data_ptr);
                cur-&gt;clear();
            }
        }
        swap(*this, new_unordered_map);
    }
    friend void swap(UnorderedMap&amp; ump1, UnorderedMap&amp; ump2){
        swap(ump1._bucket_count, ump2._bucket_count);
        swap(ump1._mask, ump2._mask);
        swap(ump1._data_count, ump2._data_count);
        swap(ump1._buckets, ump2._buckets);
    }

private:
    unsigned int _bucket_count, _mask, _data_count;
    bucket *_buckets;
public:
    const float MAX_LOAD_FACTOR = 0.5f;
    const float MIN_LOAD_FACTOR = 0.1f;
    const unsigned int DOWNSIZE_THRESHOLD = 16u;
    UnorderedMap(unsigned int bucket_size = 1u)
     : _bucket_count(ceilpow2(max(bucket_size, 1u))), _mask(_bucket_count - 1),
        _data_count(0u), _buckets(new bucket[_bucket_count + 1]){
        _buckets[_bucket_count - 1]._last = true, _buckets[_bucket_count]._end = true;
    }
    ~UnorderedMap(){ delete[] _buckets; }
    friend ostream&amp; operator&lt;&lt; (ostream&amp; os, UnorderedMap&amp; ump) noexcept {
        for(data_type&amp; val : ump) os &lt;&lt; '{' &lt;&lt; val.first &lt;&lt; ',' &lt;&lt; val.second &lt;&lt; &quot;} &quot;;
        return os;
    }
    _Tp&amp; operator[](const _Key&amp; key){
        return _find(key, true)-&gt;data_ptr()-&gt;second;
    }
    const _Tp&amp; at(const _Key&amp; key){
        bucket *res = _find(key);
        if(res == _buckets + _bucket_count) __throw_out_of_range(__N(&quot;Unordered_Map::at&quot;));
        return res-&gt;data_ptr()-&gt;second;
    }
    void clear(){
        UnorderedMap new_unordered_set(1u);
        swap(*this, new_unordered_set);
    }
    size_t size() const noexcept { return _data_count; }
    size_t bucket_count() const noexcept { return _bucket_count; }
    bool empty() const noexcept { return (_data_count == 0); }
    iterator begin() const noexcept { return _buckets-&gt;empty() ? iterator(increment(_buckets)) : iterator(_buckets); }
    iterator end() const noexcept { return iterator(_buckets + _bucket_count); }
    iterator find(const _Key&amp; key){ return iterator(_find(key)); }
    iterator insert(const data_type&amp; data){ return iterator(_insert(data)); }
    iterator erase(const _Key&amp; key){ return iterator(erase_key(key)); }
    iterator erase(const iterator&amp; itr){ return iterator(erase_itr(itr.bucket_ptr)); }
    void simple_erase(const _Key&amp; key){ erase_key(key, false); }
    void simple_erase(const iterator&amp; itr){ erase_itr(itr.bucket_ptr, false); }

    // DEBUG 用
    short int maximum_distance() const noexcept {
        short int ret = -1;
        for(bucket *cur = _buckets; !cur-&gt;_end; ++cur){
            ret = max(ret, cur-&gt;_dist);
        }
        return ret;
    }
};

template&lt;class _Key, class _Tp, class _Hash, bool DOWNSIZE&gt;
class UnorderedMapIterator {
private:
    friend UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    typename UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::bucket *bucket_ptr;
    using iterator_category = forward_iterator_tag;
    using value_type = pair&lt;_Key, _Tp&gt;;
    using difference_type = ptrdiff_t;
    using pointer = pair&lt;_Key, _Tp&gt;*;
    using reference = pair&lt;_Key, _Tp&gt;&amp;;

private:
    UnorderedMapIterator(typename UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::bucket *_bucket_ptr)
        noexcept : bucket_ptr(_bucket_ptr){}
public:
    UnorderedMapIterator() noexcept : bucket_ptr(){}
    UnorderedMapIterator(const UnorderedMapIterator&amp; itr) noexcept : bucket_ptr(itr.bucket_ptr){}
    UnorderedMapIterator&amp; operator=(const UnorderedMapIterator&amp; itr)
        &amp; noexcept { return bucket_ptr = itr.bucket_ptr, *this; }
    UnorderedMapIterator&amp; operator=(const UnorderedMapIterator&amp;&amp; itr)
        &amp; noexcept { return bucket_ptr = itr.bucket_ptr, *this; }
    reference operator*() const noexcept { return bucket_ptr-&gt;data(); }
    pointer operator-&gt;() const noexcept { return bucket_ptr-&gt;data_ptr(); }
    UnorderedMapIterator&amp; operator++() noexcept {
        return bucket_ptr = UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::increment(bucket_ptr), *this;
    }
    UnorderedMapIterator operator++(int) const noexcept {
        return UnorderedMapIterator(UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::increment(this-&gt;bucket_ptr));
    }
    bool operator==(const UnorderedMapIterator&amp; itr) const noexcept { return !(*this != itr); };
    bool operator!=(const UnorderedMapIterator&amp; itr) const noexcept { return bucket_ptr != itr.bucket_ptr; }
};
</pre>
<h3>コード(高速版)</h3>
<div class="codebox">
<input type="checkbox" id="label" class="csscode" />
<label for="label"></label>
<pre class="prettyprint linenums">
template&lt;class _Key, class _Tp, class _Hash, bool DOWNSIZE&gt; class UnorderedMapIterator;

template&lt;class _Key, class _Tp, class _Hash = hash&lt;_Key&gt;, bool DOWNSIZE = false&gt;
class UnorderedMap
{
private:
    using iterator = UnorderedMapIterator&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    using value_type = _Tp;
    using data_type = pair&lt;_Key, _Tp&gt;;
    using aligned_pointer = typename aligned_storage&lt;sizeof(value_type), alignof(value_type)&gt;::type;
    friend UnorderedMapIterator&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    struct bucket {
        _Key _key;
        short int _dist;
        bool _last, _end;
        aligned_pointer _value_ptr;
        bucket() noexcept : _dist(-1), _last(false), _end(false){}
        ~bucket(){ if(!empty()) _delete(); }
        inline void clear() noexcept { _dist = -1; }
        inline void _delete(){ _dist = -1, value_ptr()-&gt;~value_type(); }
        inline bool empty() const noexcept { return (_dist == -1); }
        inline value_type&amp; value() noexcept {
            return *reinterpret_cast&lt;value_type*&gt;(&amp;_value_ptr);
        }
        inline value_type* value_ptr() noexcept {
            return reinterpret_cast&lt;value_type*&gt;(&amp;_value_ptr);
        }
        inline void new_value(const value_type&amp; value){
            new(&amp;_value_ptr) value_type(value);
        }
    };
    inline static unsigned int ceilpow2(unsigned int u) noexcept {
        --u, u |= u &gt;&gt; 1, u |= u &gt;&gt; 2, u |= u &gt;&gt; 4, u |= u &gt;&gt; 8;
        return (u | (u &gt;&gt; 16)) + 1;
    }
    inline static bucket *increment(bucket *cur) noexcept {
        for(++cur; !cur-&gt;_end; ++cur){
            if(!cur-&gt;empty()) break;
        }
        return cur;
    }
    inline bucket *next_bucket(bucket *cur) const noexcept {
        return cur-&gt;_last ? _buckets : cur + 1;
    }
    inline unsigned int make_hash(const _Key&amp; key) const noexcept {
        return _Hash()(key);
    }
    inline float load_factor() const noexcept {
        return (float)_data_count / _bucket_count;
    }
    bucket *insert_impl(bucket *cur, _Key key, short int dist, value_type value){
        bucket *ret = cur;
        bool flag = false;
        while(true){
            if(cur-&gt;empty()){
                cur-&gt;_key = key, cur-&gt;_dist = dist, cur-&gt;new_value(value);
                if(!flag) ret = cur, flag = true;
                break;
            }else if(dist &gt; cur-&gt;_dist){
                swap(key, cur-&gt;_key), swap(dist, cur-&gt;_dist), swap(value, cur-&gt;value());
                if(!flag) ret = cur, flag = true;
            }
            ++dist;
            cur = next_bucket(cur);
        }
        return ret;
    }
    bucket *_find(const _Key&amp; key, bool push=false){
        bucket *cur = _buckets + (make_hash(key) &amp; _mask);
        short int dist = 0;
        while(dist &lt;= cur-&gt;_dist){
            if(key == cur-&gt;_key) return cur;
            ++dist;
            cur = next_bucket(cur);
        }
        if(!push) return _buckets + _bucket_count;
        ++_data_count;
        if(rehash_check()){
            cur = _buckets + (make_hash(key) &amp; _mask), dist = 0;
        }
        return insert_impl(cur, key, dist, _Tp());
    }
    bucket *_insert(const data_type&amp; data){
        const _Key&amp; key = data.first;
        bucket *cur = _buckets + (make_hash(key) &amp; _mask);
        short int dist = 0;
        while(dist &lt;= cur-&gt;_dist){
            if(key == cur-&gt;_key) return cur;
            ++dist;
            cur = next_bucket(cur);
        }
        ++_data_count;
        if(rehash_check()){
            cur = _buckets + (make_hash(key) &amp; _mask), dist = 0;
        }
        return insert_impl(cur, key, dist, data.second);
    }
    bucket *backward_shift(bucket *cur, bool next_ret){
        bucket *next = next_bucket(cur), *ret = cur;
        if(next-&gt;_dist &lt; 1) return next_ret ? increment(cur) : cur;
        do {
            cur-&gt;_key = next-&gt;_key;
            cur-&gt;_dist = next-&gt;_dist - 1;
            cur-&gt;_value_ptr = next-&gt;_value_ptr;
            cur = next, next = next_bucket(cur);
        }while(next-&gt;_dist &gt;= 1);
        cur-&gt;clear();
        return ret;
    }
    bucket *erase_impl(bucket *cur, bool next_ret){
        assert(cur != _buckets + _bucket_count);
        cur-&gt;_delete();
        return backward_shift(cur, next_ret);
    }
    bucket *erase_itr(bucket *cur, bool next_ret = true){
        --_data_count;
        const _Key&amp; key = cur-&gt;_key;
        return erase_impl(rehash_check() ? _find(key) : cur, next_ret);
    }
    bucket *erase_key(const _Key&amp; key, bool next_ret = true){
        --_data_count;
        rehash_check();
        return erase_impl(_find(key), next_ret);
    }
    bool rehash_check(){
        if(load_factor() &gt;= MAX_LOAD_FACTOR){
            rehash(_bucket_count * 2);
            return true;
        }else if(DOWNSIZE){
            if(load_factor() &lt;= MIN_LOAD_FACTOR &amp;&amp; _bucket_count &gt;= DOWNSIZE_THRESHOLD){
                rehash(_bucket_count / 2);
                return true;
            }else{
                return false;
            }
        }else{
            return false;
        }
    }
    void move_data(_Key key, aligned_pointer value_ptr){
        bucket *cur = _buckets + (make_hash(key) &amp; _mask);
        short int dist = 0;
        while(true){
            if(cur-&gt;empty()){
                cur-&gt;_key = key, cur-&gt;_dist = dist, cur-&gt;_value_ptr = value_ptr;
                break;
            }else if(dist &gt; cur-&gt;_dist){
                swap(key, cur-&gt;_key), swap(dist, cur-&gt;_dist), swap(value_ptr, cur-&gt;_value_ptr);
            }
            ++dist;
            cur = next_bucket(cur);
        }
    }
    void rehash(unsigned int new_bucket_count){
        UnorderedMap new_unordered_map(new_bucket_count);
        new_unordered_map._data_count = _data_count;
        for(bucket *cur = _buckets; !cur-&gt;_end; ++cur){
            if(!cur-&gt;empty()){
                new_unordered_map.move_data(cur-&gt;_key, cur-&gt;_value_ptr);
                cur-&gt;clear();
            }
        }
        swap(*this, new_unordered_map);
    }
    friend void swap(UnorderedMap&amp; ump1, UnorderedMap&amp; ump2){
        swap(ump1._bucket_count, ump2._bucket_count);
        swap(ump1._mask, ump2._mask);
        swap(ump1._data_count, ump2._data_count);
        swap(ump1._buckets, ump2._buckets);
    }

private:
    unsigned int _bucket_count, _mask, _data_count;
    bucket *_buckets;
public:
    const float MAX_LOAD_FACTOR = 0.5f;
    const float MIN_LOAD_FACTOR = 0.1f;
    const unsigned int DOWNSIZE_THRESHOLD = 16u;
    UnorderedMap(unsigned int bucket_size = 1u)
     : _bucket_count(ceilpow2(max(bucket_size, 1u))), _mask(_bucket_count - 1),
        _data_count(0u), _buckets(new bucket[_bucket_count + 1]){
        _buckets[_bucket_count - 1]._last = true, _buckets[_bucket_count]._end = true;
    }
    ~UnorderedMap(){ delete[] _buckets; }
    friend ostream&amp; operator&lt;&lt; (ostream&amp; os, UnorderedMap&amp; ump) noexcept {
        for(auto val : ump) os &lt;&lt; '{' &lt;&lt; val.first &lt;&lt; ',' &lt;&lt; val.second &lt;&lt; &quot;} &quot;;
        return os;
    }
    _Tp&amp; operator[](const _Key&amp; key){
        return _find(key, true)-&gt;value();
    }
    const _Tp&amp; at(const _Key&amp; key){
        bucket *res = _find(key);
        if(res == _buckets + _bucket_count) __throw_out_of_range(__N(&quot;Unordered_Map::at&quot;));
        return res-&gt;value();
    }
    void clear(){
        UnorderedMap new_unordered_map(1u);
        swap(*this, new_unordered_map);
    }
    size_t size() const noexcept { return _data_count; }
    size_t bucket_count() const noexcept { return _bucket_count; }
    bool empty() const noexcept { return (_data_count == 0); }
    iterator begin() const noexcept { return _buckets-&gt;empty() ? iterator(increment(_buckets)) : iterator(_buckets); }
    iterator end() const noexcept { return iterator(_buckets + _bucket_count); }
    iterator find(const _Key&amp; key){ return iterator(_find(key)); }
    iterator insert(const data_type&amp; data){ return iterator(_insert(data)); }
    iterator erase(const _Key&amp; key){ return iterator(erase_key(key)); }
    iterator erase(const iterator&amp; itr){ return iterator(erase_itr(itr.bucket_ptr)); }
    void simple_erase(const _Key&amp; key){ erase_key(key, false); }
    void simple_erase(const iterator&amp; itr){ erase_itr(itr.bucket_ptr, false); }

    // DEBUG 用
    short int maximum_distance() const noexcept {
        short int ret = -1;
        for(bucket *cur = _buckets; !cur-&gt;_end; ++cur){
            ret = max(ret, cur-&gt;_dist);
        }
        return ret;
    }
};

template&lt;class _Key, class _Tp, class _Hash, bool DOWNSIZE&gt;
class UnorderedMapIterator {
private:
    friend UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;;
    typename UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::bucket *bucket_ptr;
    using iterator_category = forward_iterator_tag;
    using value_type = pair&lt;const _Key, _Tp&gt;;
    using difference_type = ptrdiff_t;
    using reference = pair&lt;const _Key&amp;, _Tp&amp;&gt;;

private:
    UnorderedMapIterator(typename UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::bucket *_bucket_ptr)
        noexcept : bucket_ptr(_bucket_ptr){}
public:
    UnorderedMapIterator() noexcept : bucket_ptr(){}
    UnorderedMapIterator(const UnorderedMapIterator&amp; itr) noexcept : bucket_ptr(itr.bucket_ptr){}
    UnorderedMapIterator&amp; operator=(const UnorderedMapIterator&amp; itr)
        &amp; noexcept { return bucket_ptr = itr.bucket_ptr, *this; }
    UnorderedMapIterator&amp; operator=(const UnorderedMapIterator&amp;&amp; itr)
        &amp; noexcept { return bucket_ptr = itr.bucket_ptr, *this; }
    reference operator*() const noexcept { return {bucket_ptr-&gt;_key, bucket_ptr-&gt;value()}; }
    UnorderedMapIterator&amp; operator++() noexcept {
        return bucket_ptr = UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::increment(bucket_ptr), *this;
    }
    UnorderedMapIterator operator++(int) const noexcept {
        return UnorderedMapIterator(UnorderedMap&lt;_Key, _Tp, _Hash, DOWNSIZE&gt;::increment(this-&gt;bucket_ptr));
    }
    bool operator==(const UnorderedMapIterator&amp; itr) const noexcept { return !(*this != itr); };
    bool operator!=(const UnorderedMapIterator&amp; itr) const noexcept { return bucket_ptr != itr.bucket_ptr; }
};
</pre>
<h3>verify 用の問題</h3>
<p>Atcoder : <a href=""></a>
  <a href="">提出コード</a></p>
<p>Codeforces : <a href=""></a>
  <a href="">提出コード</a></p>
</section>

</div>
<!--/contents-->

<footer>
<small>Copyright&copy; <a href="../../index.html"> My Algorithm : kopricky アルゴリズムライブラリ </a> All Rights Reserved.</small>
<span class="pr">《<a href="https://template-party.com/" target="_blank">Web Design:Template-Party</a>》</span>
</footer>

<script src="../../js/prettify.js"></script>
<script src="../../js/lang-css.js"></script>
<!-- prettyPrint()関数を実行するため追加↓ -->
<script>prettyPrint();</script>

</div>
<!--/container-->

</body>
</html>
